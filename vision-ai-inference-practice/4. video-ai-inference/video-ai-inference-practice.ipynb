{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import yt_dlp\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "# from moviepy.editor import ImageSequenceClip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Yutube 영상 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtube.com/shorts/6HD91e1iKiM?si=gMXt3J3qVekSbOpE\n",
      "[youtube] 6HD91e1iKiM: Downloading webpage\n",
      "[youtube] 6HD91e1iKiM: Downloading ios player API JSON\n",
      "[youtube] 6HD91e1iKiM: Downloading mweb player API JSON\n",
      "[youtube] 6HD91e1iKiM: Downloading m3u8 information\n",
      "[info] 6HD91e1iKiM: Downloading 1 format(s): 18\n",
      "[download] Destination: downloaded_video.mp4\n",
      "[download] 100% of    1.64MiB in 00:00:00 at 4.07MiB/s   \n"
     ]
    }
   ],
   "source": [
    "# 다운로드할 YouTube URL\n",
    "url = \"https://youtube.com/shorts/6HD91e1iKiM?si=gMXt3J3qVekSbOpE\"\n",
    "\n",
    "# yt-dlp 설정\n",
    "ydl_opts = {\n",
    "    \"format\": \"best\",\n",
    "    \"outtmpl\": \"downloaded_video.%(ext)s\",\n",
    "}\n",
    "\n",
    "# 다운로드\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([url])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 동영상의 fps 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 30.0\n"
     ]
    }
   ],
   "source": [
    "# 동영상 파일 경로\n",
    "video_path = \"downloaded_video.mp4\"\n",
    "\n",
    "# 동영상 파일 열기\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# FPS 가져오기\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"FPS:\", fps)\n",
    "\n",
    "# 동영상 파일 닫기\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 동영상을 프레임 단위로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 686개의 프레임이 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "video_path = \"downloaded_video.mp4\"\n",
    "\n",
    "# cv2를 이용해 동영상 파일 열기\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 프레임을 저장할 디렉토리 생성\n",
    "output_dir = \"frames\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 프레임 단위로 이미지로 저장\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # 이미지 파일로 프레임 저장\n",
    "    frame_path = os.path.join(output_dir, f\"frame_{frame_count:04d}.jpg\")\n",
    "    cv2.imwrite(frame_path, frame)\n",
    "    frame_count += 1\n",
    "\n",
    "# 동영상 파일 닫기\n",
    "cap.release()\n",
    "print(f\"총 {frame_count}개의 프레임이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. YOLOv8 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디렉토리 'results'가 이미 존재해.\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0028.jpg: 640x384 3 persons, 37.9ms\n",
      "Speed: 0.8ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0014.jpg: 640x384 6 persons, 30.5ms\n",
      "Speed: 0.6ms preprocess, 30.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0000.jpg: 640x384 5 persons, 34.2ms\n",
      "Speed: 0.4ms preprocess, 34.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0558.jpg: 640x384 7 persons, 30.8ms\n",
      "Speed: 0.5ms preprocess, 30.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0216.jpg: 640x384 6 persons, 32.6ms\n",
      "Speed: 0.5ms preprocess, 32.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0570.jpg: 640x384 6 persons, 31.5ms\n",
      "Speed: 0.5ms preprocess, 31.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0564.jpg: 640x384 7 persons, 27.7ms\n",
      "Speed: 0.5ms preprocess, 27.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0202.jpg: 640x384 5 persons, 27.7ms\n",
      "Speed: 0.6ms preprocess, 27.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0389.jpg: 640x384 5 persons, 27.5ms\n",
      "Speed: 0.6ms preprocess, 27.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0438.jpg: 640x384 7 persons, 27.8ms\n",
      "Speed: 0.5ms preprocess, 27.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0362.jpg: 640x384 3 persons, 30.2ms\n",
      "Speed: 0.5ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0404.jpg: 640x384 3 persons, 1 cell phone, 29.3ms\n",
      "Speed: 0.5ms preprocess, 29.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0410.jpg: 640x384 5 persons, 26.9ms\n",
      "Speed: 0.5ms preprocess, 26.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0376.jpg: 640x384 3 persons, 28.1ms\n",
      "Speed: 0.5ms preprocess, 28.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0148.jpg: 640x384 7 persons, 32.8ms\n",
      "Speed: 0.5ms preprocess, 32.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0606.jpg: 640x384 5 persons, 32.9ms\n",
      "Speed: 0.6ms preprocess, 32.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0160.jpg: 640x384 4 persons, 26.8ms\n",
      "Speed: 0.5ms preprocess, 26.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0174.jpg: 640x384 2 persons, 31.1ms\n",
      "Speed: 0.5ms preprocess, 31.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0612.jpg: 640x384 4 persons, 28.6ms\n",
      "Speed: 0.5ms preprocess, 28.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0175.jpg: 640x384 2 persons, 30.5ms\n",
      "Speed: 0.6ms preprocess, 30.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0613.jpg: 640x384 3 persons, 30.1ms\n",
      "Speed: 0.5ms preprocess, 30.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0607.jpg: 640x384 5 persons, 32.4ms\n",
      "Speed: 0.5ms preprocess, 32.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0161.jpg: 640x384 4 persons, 28.3ms\n",
      "Speed: 0.5ms preprocess, 28.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0149.jpg: 640x384 5 persons, 29.2ms\n",
      "Speed: 0.5ms preprocess, 29.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0411.jpg: 640x384 6 persons, 29.7ms\n",
      "Speed: 0.5ms preprocess, 29.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0377.jpg: 640x384 3 persons, 28.3ms\n",
      "Speed: 0.4ms preprocess, 28.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0363.jpg: 640x384 3 persons, 30.1ms\n",
      "Speed: 0.5ms preprocess, 30.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0405.jpg: 640x384 4 persons, 33.4ms\n",
      "Speed: 0.6ms preprocess, 33.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0439.jpg: 640x384 7 persons, 36.6ms\n",
      "Speed: 0.7ms preprocess, 36.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0388.jpg: 640x384 4 persons, 33.8ms\n",
      "Speed: 0.7ms preprocess, 33.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0565.jpg: 640x384 5 persons, 34.1ms\n",
      "Speed: 0.6ms preprocess, 34.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0203.jpg: 640x384 6 persons, 33.7ms\n",
      "Speed: 0.5ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0217.jpg: 640x384 6 persons, 33.0ms\n",
      "Speed: 0.6ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0571.jpg: 640x384 7 persons, 33.0ms\n",
      "Speed: 0.7ms preprocess, 33.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0559.jpg: 640x384 7 persons, 34.1ms\n",
      "Speed: 0.6ms preprocess, 34.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0001.jpg: 640x384 7 persons, 32.9ms\n",
      "Speed: 0.6ms preprocess, 32.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0015.jpg: 640x384 4 persons, 41.0ms\n",
      "Speed: 0.5ms preprocess, 41.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0029.jpg: 640x384 4 persons, 37.0ms\n",
      "Speed: 0.6ms preprocess, 37.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0003.jpg: 640x384 4 persons, 37.5ms\n",
      "Speed: 0.6ms preprocess, 37.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0017.jpg: 640x384 4 persons, 36.3ms\n",
      "Speed: 0.5ms preprocess, 36.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0598.jpg: 640x384 3 persons, 37.2ms\n",
      "Speed: 0.5ms preprocess, 37.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0229.jpg: 640x384 5 persons, 37.6ms\n",
      "Speed: 0.5ms preprocess, 37.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0201.jpg: 640x384 5 persons, 32.3ms\n",
      "Speed: 0.5ms preprocess, 32.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0567.jpg: 640x384 5 persons, 35.1ms\n",
      "Speed: 0.7ms preprocess, 35.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0573.jpg: 640x384 5 persons, 29.4ms\n",
      "Speed: 0.5ms preprocess, 29.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0215.jpg: 640x384 6 persons, 30.8ms\n",
      "Speed: 0.5ms preprocess, 30.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0349.jpg: 640x384 2 persons, 29.0ms\n",
      "Speed: 0.5ms preprocess, 29.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0375.jpg: 640x384 4 persons, 30.5ms\n",
      "Speed: 0.5ms preprocess, 30.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0413.jpg: 640x384 5 persons, 34.2ms\n",
      "Speed: 0.5ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0407.jpg: 640x384 7 persons, 36.8ms\n",
      "Speed: 0.5ms preprocess, 36.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0361.jpg: 640x384 3 persons, 35.2ms\n",
      "Speed: 0.7ms preprocess, 35.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0188.jpg: 640x384 5 persons, 38.5ms\n",
      "Speed: 0.7ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0639.jpg: 640x384 2 persons, 36.4ms\n",
      "Speed: 0.6ms preprocess, 36.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0611.jpg: 640x384 4 persons, 37.0ms\n",
      "Speed: 0.6ms preprocess, 37.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0177.jpg: 640x384 2 persons, 32.6ms\n",
      "Speed: 0.5ms preprocess, 32.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0163.jpg: 640x384 5 persons, 32.9ms\n",
      "Speed: 0.5ms preprocess, 32.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0605.jpg: 640x384 3 persons, 31.0ms\n",
      "Speed: 0.5ms preprocess, 31.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0162.jpg: 640x384 5 persons, 32.7ms\n",
      "Speed: 0.5ms preprocess, 32.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0604.jpg: 640x384 4 persons, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0610.jpg: 640x384 3 persons, 29.9ms\n",
      "Speed: 0.4ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0176.jpg: 640x384 2 persons, 32.5ms\n",
      "Speed: 1.0ms preprocess, 32.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0638.jpg: 640x384 1 person, 32.1ms\n",
      "Speed: 0.4ms preprocess, 32.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0189.jpg: 640x384 6 persons, 33.7ms\n",
      "Speed: 0.6ms preprocess, 33.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0406.jpg: 640x384 6 persons, 33.5ms\n",
      "Speed: 0.6ms preprocess, 33.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0360.jpg: 640x384 2 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0374.jpg: 640x384 4 persons, 30.7ms\n",
      "Speed: 0.5ms preprocess, 30.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0412.jpg: 640x384 6 persons, 38.4ms\n",
      "Speed: 0.5ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0348.jpg: 640x384 4 persons, 32.2ms\n",
      "Speed: 0.6ms preprocess, 32.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0572.jpg: 640x384 5 persons, 31.7ms\n",
      "Speed: 0.5ms preprocess, 31.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0214.jpg: 640x384 7 persons, 31.8ms\n",
      "Speed: 0.5ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0200.jpg: 640x384 5 persons, 35.9ms\n",
      "Speed: 0.5ms preprocess, 35.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0566.jpg: 640x384 6 persons, 35.1ms\n",
      "Speed: 0.5ms preprocess, 35.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0228.jpg: 640x384 6 persons, 34.2ms\n",
      "Speed: 0.5ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0599.jpg: 640x384 3 persons, 35.9ms\n",
      "Speed: 0.5ms preprocess, 35.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0016.jpg: 640x384 4 persons, 35.2ms\n",
      "Speed: 0.5ms preprocess, 35.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0002.jpg: 640x384 5 persons, 30.0ms\n",
      "Speed: 0.7ms preprocess, 30.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0006.jpg: 640x384 5 persons, 33.5ms\n",
      "Speed: 0.4ms preprocess, 33.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0012.jpg: 640x384 5 persons, 31.2ms\n",
      "Speed: 0.5ms preprocess, 31.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0589.jpg: 640x384 4 persons, 32.8ms\n",
      "Speed: 0.5ms preprocess, 32.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0562.jpg: 640x384 5 persons, 1 cell phone, 35.4ms\n",
      "Speed: 0.4ms preprocess, 35.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0204.jpg: 640x384 5 persons, 34.9ms\n",
      "Speed: 0.5ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0210.jpg: 640x384 5 persons, 33.2ms\n",
      "Speed: 0.4ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0576.jpg: 640x384 6 persons, 36.5ms\n",
      "Speed: 0.6ms preprocess, 36.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0238.jpg: 640x384 5 persons, 34.2ms\n",
      "Speed: 0.5ms preprocess, 34.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0416.jpg: 640x384 5 persons, 30.3ms\n",
      "Speed: 0.6ms preprocess, 30.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0370.jpg: 640x384 3 persons, 35.4ms\n",
      "Speed: 0.5ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0364.jpg: 640x384 2 persons, 28.6ms\n",
      "Speed: 0.5ms preprocess, 28.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0402.jpg: 640x384 2 persons, 32.6ms\n",
      "Speed: 0.5ms preprocess, 32.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0358.jpg: 640x384 1 person, 29.3ms\n",
      "Speed: 0.5ms preprocess, 29.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0199.jpg: 640x384 6 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0172.jpg: 640x384 2 persons, 33.9ms\n",
      "Speed: 0.6ms preprocess, 33.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0614.jpg: 640x384 4 persons, 39.8ms\n",
      "Speed: 0.5ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0600.jpg: 640x384 3 persons, 36.2ms\n",
      "Speed: 0.5ms preprocess, 36.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0166.jpg: 640x384 5 persons, 31.7ms\n",
      "Speed: 0.5ms preprocess, 31.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0628.jpg: 640x384 2 persons, 32.6ms\n",
      "Speed: 0.4ms preprocess, 32.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0629.jpg: 640x384 1 person, 34.0ms\n",
      "Speed: 0.6ms preprocess, 34.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0601.jpg: 640x384 4 persons, 31.5ms\n",
      "Speed: 0.5ms preprocess, 31.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0167.jpg: 640x384 4 persons, 34.8ms\n",
      "Speed: 0.5ms preprocess, 34.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0173.jpg: 640x384 3 persons, 34.2ms\n",
      "Speed: 0.5ms preprocess, 34.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0615.jpg: 640x384 1 person, 40.0ms\n",
      "Speed: 0.4ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0198.jpg: 640x384 5 persons, 36.5ms\n",
      "Speed: 0.5ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0359.jpg: 640x384 1 person, 33.2ms\n",
      "Speed: 0.5ms preprocess, 33.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0365.jpg: 640x384 2 persons, 32.7ms\n",
      "Speed: 0.5ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0403.jpg: 640x384 3 persons, 1 cell phone, 32.9ms\n",
      "Speed: 0.5ms preprocess, 32.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0417.jpg: 640x384 6 persons, 33.9ms\n",
      "Speed: 0.5ms preprocess, 33.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0371.jpg: 640x384 2 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0239.jpg: 640x384 5 persons, 31.1ms\n",
      "Speed: 0.5ms preprocess, 31.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0211.jpg: 640x384 5 persons, 30.7ms\n",
      "Speed: 0.5ms preprocess, 30.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0577.jpg: 640x384 6 persons, 35.8ms\n",
      "Speed: 0.5ms preprocess, 35.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0563.jpg: 640x384 5 persons, 31.2ms\n",
      "Speed: 0.4ms preprocess, 31.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0205.jpg: 640x384 6 persons, 29.4ms\n",
      "Speed: 0.5ms preprocess, 29.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0588.jpg: 640x384 5 persons, 30.5ms\n",
      "Speed: 0.5ms preprocess, 30.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0013.jpg: 640x384 5 persons, 32.2ms\n",
      "Speed: 0.4ms preprocess, 32.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0007.jpg: 640x384 5 persons, 27.6ms\n",
      "Speed: 0.5ms preprocess, 27.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0011.jpg: 640x384 6 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0005.jpg: 640x384 3 persons, 30.1ms\n",
      "Speed: 0.4ms preprocess, 30.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0039.jpg: 640x384 7 persons, 32.9ms\n",
      "Speed: 0.5ms preprocess, 32.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0575.jpg: 640x384 5 persons, 37.5ms\n",
      "Speed: 0.5ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0213.jpg: 640x384 6 persons, 36.4ms\n",
      "Speed: 0.5ms preprocess, 36.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0207.jpg: 640x384 7 persons, 35.2ms\n",
      "Speed: 0.6ms preprocess, 35.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0561.jpg: 640x384 5 persons, 1 cell phone, 32.5ms\n",
      "Speed: 0.4ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0549.jpg: 640x384 4 persons, 1 skateboard, 31.1ms\n",
      "Speed: 0.5ms preprocess, 31.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0398.jpg: 640x384 3 persons, 27.4ms\n",
      "Speed: 0.6ms preprocess, 27.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0401.jpg: 640x384 2 persons, 1 skateboard, 34.5ms\n",
      "Speed: 0.5ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0367.jpg: 640x384 3 persons, 28.2ms\n",
      "Speed: 0.5ms preprocess, 28.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0373.jpg: 640x384 3 persons, 28.5ms\n",
      "Speed: 0.5ms preprocess, 28.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0415.jpg: 640x384 5 persons, 29.8ms\n",
      "Speed: 0.5ms preprocess, 29.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0429.jpg: 640x384 6 persons, 32.1ms\n",
      "Speed: 0.6ms preprocess, 32.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0165.jpg: 640x384 5 persons, 33.2ms\n",
      "Speed: 0.5ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0603.jpg: 640x384 4 persons, 30.2ms\n",
      "Speed: 0.6ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0617.jpg: 640x384 2 persons, 31.8ms\n",
      "Speed: 1.1ms preprocess, 31.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0171.jpg: 640x384 3 persons, 32.5ms\n",
      "Speed: 0.5ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0159.jpg: 640x384 4 persons, 33.3ms\n",
      "Speed: 0.5ms preprocess, 33.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0158.jpg: 640x384 3 persons, 32.3ms\n",
      "Speed: 0.5ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0616.jpg: 640x384 2 persons, 34.0ms\n",
      "Speed: 0.5ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0170.jpg: 640x384 3 persons, 33.0ms\n",
      "Speed: 0.5ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0164.jpg: 640x384 5 persons, 30.0ms\n",
      "Speed: 0.6ms preprocess, 30.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0602.jpg: 640x384 4 persons, 34.0ms\n",
      "Speed: 0.6ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0428.jpg: 640x384 4 persons, 30.9ms\n",
      "Speed: 0.6ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0372.jpg: 640x384 3 persons, 33.3ms\n",
      "Speed: 0.5ms preprocess, 33.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0414.jpg: 640x384 4 persons, 32.5ms\n",
      "Speed: 0.5ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0400.jpg: 640x384 3 persons, 31.8ms\n",
      "Speed: 0.5ms preprocess, 31.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0366.jpg: 640x384 2 persons, 33.9ms\n",
      "Speed: 0.5ms preprocess, 33.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0399.jpg: 640x384 2 persons, 28.4ms\n",
      "Speed: 0.4ms preprocess, 28.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0548.jpg: 640x384 5 persons, 37.7ms\n",
      "Speed: 0.6ms preprocess, 37.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0206.jpg: 640x384 5 persons, 31.7ms\n",
      "Speed: 0.4ms preprocess, 31.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0560.jpg: 640x384 5 persons, 1 cell phone, 34.5ms\n",
      "Speed: 0.5ms preprocess, 34.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0574.jpg: 640x384 5 persons, 30.2ms\n",
      "Speed: 0.5ms preprocess, 30.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0212.jpg: 640x384 5 persons, 28.9ms\n",
      "Speed: 0.5ms preprocess, 28.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0038.jpg: 640x384 8 persons, 32.2ms\n",
      "Speed: 0.4ms preprocess, 32.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0004.jpg: 640x384 3 persons, 32.9ms\n",
      "Speed: 0.5ms preprocess, 32.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0010.jpg: 640x384 6 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0088.jpg: 640x384 1 person, 30.8ms\n",
      "Speed: 0.6ms preprocess, 30.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0077.jpg: 640x384 3 persons, 34.1ms\n",
      "Speed: 0.4ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0063.jpg: 640x384 5 persons, 35.4ms\n",
      "Speed: 0.5ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0249.jpg: 640x384 4 persons, 35.3ms\n",
      "Speed: 0.5ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0513.jpg: 640x384 1 person, 36.8ms\n",
      "Speed: 0.6ms preprocess, 36.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0275.jpg: 640x384 3 persons, 33.7ms\n",
      "Speed: 0.5ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0261.jpg: 640x384 3 persons, 32.9ms\n",
      "Speed: 0.5ms preprocess, 32.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0507.jpg: 640x384 2 persons, 36.2ms\n",
      "Speed: 0.5ms preprocess, 36.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0498.jpg: 640x384 2 persons, 1 cow, 1 tv, 37.6ms\n",
      "Speed: 0.5ms preprocess, 37.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0329.jpg: 640x384 2 persons, 31.5ms\n",
      "Speed: 0.5ms preprocess, 31.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0467.jpg: 640x384 1 person, 35.6ms\n",
      "Speed: 0.4ms preprocess, 35.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0301.jpg: 640x384 4 persons, 30.7ms\n",
      "Speed: 0.5ms preprocess, 30.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0315.jpg: 640x384 2 persons, 31.8ms\n",
      "Speed: 0.5ms preprocess, 31.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0473.jpg: 640x384 2 persons, 29.2ms\n",
      "Speed: 0.5ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0659.jpg: 640x384 4 persons, 32.5ms\n",
      "Speed: 0.6ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0103.jpg: 640x384 7 persons, 33.5ms\n",
      "Speed: 0.5ms preprocess, 33.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0665.jpg: 640x384 4 persons, 33.7ms\n",
      "Speed: 0.4ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0671.jpg: 640x384 1 person, 32.7ms\n",
      "Speed: 0.7ms preprocess, 32.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0117.jpg: 640x384 9 persons, 39.5ms\n",
      "Speed: 0.5ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0670.jpg: 640x384 1 person, 30.3ms\n",
      "Speed: 0.5ms preprocess, 30.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0116.jpg: 640x384 9 persons, 28.4ms\n",
      "Speed: 0.5ms preprocess, 28.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0102.jpg: 640x384 6 persons, 32.7ms\n",
      "Speed: 0.4ms preprocess, 32.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0664.jpg: 640x384 3 persons, 28.7ms\n",
      "Speed: 0.5ms preprocess, 28.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0658.jpg: 640x384 3 persons, 30.9ms\n",
      "Speed: 0.5ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0314.jpg: 640x384 2 persons, 27.1ms\n",
      "Speed: 0.4ms preprocess, 27.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0472.jpg: 640x384 3 persons, 31.4ms\n",
      "Speed: 0.5ms preprocess, 31.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0466.jpg: 640x384 1 person, 29.1ms\n",
      "Speed: 0.5ms preprocess, 29.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0300.jpg: 640x384 6 persons, 1 sports ball, 34.5ms\n",
      "Speed: 0.4ms preprocess, 34.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0328.jpg: 640x384 5 persons, 31.9ms\n",
      "Speed: 0.4ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0499.jpg: 640x384 2 persons, 1 tv, 30.6ms\n",
      "Speed: 0.5ms preprocess, 30.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0260.jpg: 640x384 2 persons, 33.0ms\n",
      "Speed: 0.5ms preprocess, 33.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0506.jpg: 640x384 2 persons, 32.0ms\n",
      "Speed: 0.6ms preprocess, 32.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0512.jpg: 640x384 2 persons, 1 cell phone, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0274.jpg: 640x384 5 persons, 29.8ms\n",
      "Speed: 0.5ms preprocess, 29.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0248.jpg: 640x384 4 persons, 32.1ms\n",
      "Speed: 0.5ms preprocess, 32.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0062.jpg: 640x384 5 persons, 32.3ms\n",
      "Speed: 0.5ms preprocess, 32.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0076.jpg: 640x384 3 persons, 29.1ms\n",
      "Speed: 0.5ms preprocess, 29.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0089.jpg: 640x384 1 person, 34.3ms\n",
      "Speed: 0.5ms preprocess, 34.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0048.jpg: 640x384 5 persons, 31.4ms\n",
      "Speed: 0.5ms preprocess, 31.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0060.jpg: 640x384 4 persons, 31.1ms\n",
      "Speed: 0.4ms preprocess, 31.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0074.jpg: 640x384 4 persons, 24.8ms\n",
      "Speed: 0.5ms preprocess, 24.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0289.jpg: 640x384 4 persons, 24.8ms\n",
      "Speed: 0.5ms preprocess, 24.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0538.jpg: 640x384 4 persons, 24.9ms\n",
      "Speed: 0.5ms preprocess, 24.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0504.jpg: 640x384 3 persons, 25.6ms\n",
      "Speed: 0.5ms preprocess, 25.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0262.jpg: 640x384 4 persons, 25.0ms\n",
      "Speed: 0.4ms preprocess, 25.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0276.jpg: 640x384 3 persons, 24.4ms\n",
      "Speed: 0.5ms preprocess, 24.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0510.jpg: 640x384 3 persons, 27.6ms\n",
      "Speed: 0.5ms preprocess, 27.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0458.jpg: 640x384 2 persons, 25.7ms\n",
      "Speed: 0.6ms preprocess, 25.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0470.jpg: 640x384 4 persons, 24.5ms\n",
      "Speed: 0.5ms preprocess, 24.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0316.jpg: 640x384 4 persons, 25.4ms\n",
      "Speed: 0.5ms preprocess, 25.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0302.jpg: 640x384 3 persons, 26.1ms\n",
      "Speed: 0.5ms preprocess, 26.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0464.jpg: 640x384 3 persons, 25.2ms\n",
      "Speed: 0.4ms preprocess, 25.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0128.jpg: 640x384 9 persons, 24.9ms\n",
      "Speed: 0.5ms preprocess, 24.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0114.jpg: 640x384 7 persons, 24.7ms\n",
      "Speed: 0.4ms preprocess, 24.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0672.jpg: 640x384 2 persons, 24.3ms\n",
      "Speed: 0.5ms preprocess, 24.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0666.jpg: 640x384 4 persons, 25.4ms\n",
      "Speed: 0.4ms preprocess, 25.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0100.jpg: 640x384 7 persons, 24.7ms\n",
      "Speed: 0.4ms preprocess, 24.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0667.jpg: 640x384 (no detections), 24.5ms\n",
      "Speed: 0.5ms preprocess, 24.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0101.jpg: 640x384 8 persons, 25.1ms\n",
      "Speed: 0.5ms preprocess, 25.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0115.jpg: 640x384 9 persons, 25.1ms\n",
      "Speed: 0.5ms preprocess, 25.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0673.jpg: 640x384 2 persons, 26.1ms\n",
      "Speed: 0.5ms preprocess, 26.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0129.jpg: 640x384 8 persons, 26.4ms\n",
      "Speed: 0.4ms preprocess, 26.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0303.jpg: 640x384 6 persons, 26.1ms\n",
      "Speed: 0.4ms preprocess, 26.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0465.jpg: 640x384 1 person, 25.7ms\n",
      "Speed: 0.5ms preprocess, 25.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0471.jpg: 640x384 3 persons, 25.6ms\n",
      "Speed: 0.6ms preprocess, 25.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0317.jpg: 640x384 4 persons, 25.9ms\n",
      "Speed: 0.5ms preprocess, 25.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0459.jpg: 640x384 2 persons, 26.2ms\n",
      "Speed: 0.5ms preprocess, 26.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0277.jpg: 640x384 4 persons, 26.9ms\n",
      "Speed: 0.5ms preprocess, 26.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0511.jpg: 640x384 3 persons, 1 cell phone, 28.4ms\n",
      "Speed: 0.5ms preprocess, 28.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0505.jpg: 640x384 2 persons, 28.4ms\n",
      "Speed: 0.5ms preprocess, 28.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0263.jpg: 640x384 4 persons, 27.4ms\n",
      "Speed: 0.4ms preprocess, 27.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0539.jpg: 640x384 4 persons, 1 cell phone, 30.3ms\n",
      "Speed: 0.5ms preprocess, 30.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0288.jpg: 640x384 4 persons, 31.5ms\n",
      "Speed: 0.4ms preprocess, 31.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0075.jpg: 640x384 2 persons, 30.2ms\n",
      "Speed: 0.5ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0061.jpg: 640x384 4 persons, 30.4ms\n",
      "Speed: 0.5ms preprocess, 30.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0049.jpg: 640x384 4 persons, 28.6ms\n",
      "Speed: 0.5ms preprocess, 28.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0065.jpg: 640x384 5 persons, 29.0ms\n",
      "Speed: 0.5ms preprocess, 29.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0071.jpg: 640x384 5 persons, 30.6ms\n",
      "Speed: 0.5ms preprocess, 30.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0059.jpg: 640x384 3 persons, 33.9ms\n",
      "Speed: 0.6ms preprocess, 33.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0298.jpg: 640x384 4 persons, 29.2ms\n",
      "Speed: 0.5ms preprocess, 29.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0267.jpg: 640x384 2 persons, 32.0ms\n",
      "Speed: 0.5ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0501.jpg: 640x384 4 persons, 33.4ms\n",
      "Speed: 0.5ms preprocess, 33.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0515.jpg: 640x384 6 persons, 30.9ms\n",
      "Speed: 0.5ms preprocess, 30.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0273.jpg: 640x384 3 persons, 27.8ms\n",
      "Speed: 0.5ms preprocess, 27.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0529.jpg: 640x384 4 persons, 27.7ms\n",
      "Speed: 0.5ms preprocess, 27.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0313.jpg: 640x384 3 persons, 31.3ms\n",
      "Speed: 0.4ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0475.jpg: 640x384 1 person, 1 book, 32.9ms\n",
      "Speed: 0.5ms preprocess, 32.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0461.jpg: 640x384 2 persons, 30.5ms\n",
      "Speed: 0.5ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0307.jpg: 640x384 2 persons, 25.2ms\n",
      "Speed: 0.5ms preprocess, 25.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0449.jpg: 640x384 5 persons, 30.2ms\n",
      "Speed: 0.5ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0677.jpg: 640x384 2 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0111.jpg: 640x384 8 persons, 30.0ms\n",
      "Speed: 0.4ms preprocess, 30.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0105.jpg: 640x384 9 persons, 33.4ms\n",
      "Speed: 0.5ms preprocess, 33.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0663.jpg: 640x384 4 persons, 33.1ms\n",
      "Speed: 0.5ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0139.jpg: 640x384 10 persons, 34.9ms\n",
      "Speed: 0.5ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0138.jpg: 640x384 10 persons, 34.1ms\n",
      "Speed: 0.5ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0104.jpg: 640x384 8 persons, 30.7ms\n",
      "Speed: 0.6ms preprocess, 30.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0662.jpg: 640x384 4 persons, 33.3ms\n",
      "Speed: 0.4ms preprocess, 33.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0676.jpg: 640x384 4 persons, 26.8ms\n",
      "Speed: 0.5ms preprocess, 26.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0110.jpg: 640x384 8 persons, 28.0ms\n",
      "Speed: 0.6ms preprocess, 28.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0448.jpg: 640x384 5 persons, 29.4ms\n",
      "Speed: 0.5ms preprocess, 29.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0460.jpg: 640x384 3 persons, 30.8ms\n",
      "Speed: 0.5ms preprocess, 30.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0306.jpg: 640x384 4 persons, 29.0ms\n",
      "Speed: 0.4ms preprocess, 29.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0312.jpg: 640x384 3 persons, 31.5ms\n",
      "Speed: 0.4ms preprocess, 31.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0474.jpg: 640x384 2 persons, 28.2ms\n",
      "Speed: 0.5ms preprocess, 28.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0528.jpg: 640x384 3 persons, 34.7ms\n",
      "Speed: 0.5ms preprocess, 34.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0514.jpg: 640x384 4 persons, 31.1ms\n",
      "Speed: 0.4ms preprocess, 31.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0272.jpg: 640x384 4 persons, 29.4ms\n",
      "Speed: 0.6ms preprocess, 29.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0266.jpg: 640x384 3 persons, 31.9ms\n",
      "Speed: 0.5ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0500.jpg: 640x384 1 person, 1 tv, 29.8ms\n",
      "Speed: 0.5ms preprocess, 29.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0299.jpg: 640x384 5 persons, 35.8ms\n",
      "Speed: 0.5ms preprocess, 35.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0058.jpg: 640x384 3 persons, 29.5ms\n",
      "Speed: 0.6ms preprocess, 29.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0070.jpg: 640x384 3 persons, 33.2ms\n",
      "Speed: 0.5ms preprocess, 33.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0064.jpg: 640x384 5 persons, 32.5ms\n",
      "Speed: 0.7ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0099.jpg: 640x384 6 persons, 30.3ms\n",
      "Speed: 0.4ms preprocess, 30.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0072.jpg: 640x384 5 persons, 27.2ms\n",
      "Speed: 0.4ms preprocess, 27.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0066.jpg: 640x384 5 persons, 33.4ms\n",
      "Speed: 0.4ms preprocess, 33.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0270.jpg: 640x384 4 persons, 35.6ms\n",
      "Speed: 0.6ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0516.jpg: 640x384 6 persons, 33.7ms\n",
      "Speed: 0.5ms preprocess, 33.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0502.jpg: 640x384 3 persons, 31.0ms\n",
      "Speed: 0.5ms preprocess, 31.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0264.jpg: 640x384 4 persons, 30.8ms\n",
      "Speed: 0.5ms preprocess, 30.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0258.jpg: 640x384 2 persons, 32.6ms\n",
      "Speed: 0.5ms preprocess, 32.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0489.jpg: 640x384 3 persons, 1 tv, 30.9ms\n",
      "Speed: 0.5ms preprocess, 30.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0304.jpg: 640x384 6 persons, 27.9ms\n",
      "Speed: 0.7ms preprocess, 27.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0462.jpg: 640x384 1 person, 31.4ms\n",
      "Speed: 0.5ms preprocess, 31.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0476.jpg: 640x384 1 person, 1 book, 29.0ms\n",
      "Speed: 0.5ms preprocess, 29.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0310.jpg: 640x384 2 persons, 31.4ms\n",
      "Speed: 0.4ms preprocess, 31.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0338.jpg: 640x384 3 persons, 33.8ms\n",
      "Speed: 0.5ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0660.jpg: 640x384 6 persons, 31.4ms\n",
      "Speed: 0.5ms preprocess, 31.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0106.jpg: 640x384 8 persons, 34.1ms\n",
      "Speed: 0.4ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0112.jpg: 640x384 10 persons, 47.5ms\n",
      "Speed: 0.5ms preprocess, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0674.jpg: 640x384 2 persons, 30.2ms\n",
      "Speed: 0.6ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0648.jpg: 640x384 1 person, 31.6ms\n",
      "Speed: 0.6ms preprocess, 31.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0649.jpg: 640x384 2 persons, 27.9ms\n",
      "Speed: 0.4ms preprocess, 27.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0113.jpg: 640x384 9 persons, 31.9ms\n",
      "Speed: 0.4ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0675.jpg: 640x384 2 persons, 1 train, 31.0ms\n",
      "Speed: 0.5ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0661.jpg: 640x384 2 persons, 34.5ms\n",
      "Speed: 0.4ms preprocess, 34.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0107.jpg: 640x384 8 persons, 32.7ms\n",
      "Speed: 0.6ms preprocess, 32.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0339.jpg: 640x384 3 persons, 33.0ms\n",
      "Speed: 0.5ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0477.jpg: 640x384 2 persons, 1 book, 30.3ms\n",
      "Speed: 0.5ms preprocess, 30.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0311.jpg: 640x384 7 persons, 33.1ms\n",
      "Speed: 0.5ms preprocess, 33.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0305.jpg: 640x384 4 persons, 26.8ms\n",
      "Speed: 0.4ms preprocess, 26.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0463.jpg: 640x384 1 person, 30.3ms\n",
      "Speed: 0.5ms preprocess, 30.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0488.jpg: 640x384 4 persons, 29.6ms\n",
      "Speed: 0.5ms preprocess, 29.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0259.jpg: 640x384 2 persons, 40.8ms\n",
      "Speed: 0.5ms preprocess, 40.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0503.jpg: 640x384 3 persons, 36.9ms\n",
      "Speed: 0.6ms preprocess, 36.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0265.jpg: 640x384 5 persons, 44.9ms\n",
      "Speed: 0.5ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0271.jpg: 640x384 3 persons, 40.3ms\n",
      "Speed: 0.7ms preprocess, 40.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0517.jpg: 640x384 4 persons, 40.4ms\n",
      "Speed: 0.5ms preprocess, 40.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0067.jpg: 640x384 4 persons, 37.3ms\n",
      "Speed: 0.4ms preprocess, 37.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0073.jpg: 640x384 3 persons, 29.8ms\n",
      "Speed: 0.5ms preprocess, 29.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0098.jpg: 640x384 1 person, 29.3ms\n",
      "Speed: 0.5ms preprocess, 29.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0095.jpg: 640x384 3 persons, 32.9ms\n",
      "Speed: 0.5ms preprocess, 32.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0081.jpg: 640x384 3 persons, 30.4ms\n",
      "Speed: 0.5ms preprocess, 30.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0056.jpg: 640x384 7 persons, 29.0ms\n",
      "Speed: 0.5ms preprocess, 29.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0042.jpg: 640x384 6 persons, 31.5ms\n",
      "Speed: 0.5ms preprocess, 31.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0297.jpg: 640x384 3 persons, 28.6ms\n",
      "Speed: 0.5ms preprocess, 28.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0283.jpg: 640x384 3 persons, 35.0ms\n",
      "Speed: 0.6ms preprocess, 35.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0268.jpg: 640x384 4 persons, 32.8ms\n",
      "Speed: 0.5ms preprocess, 32.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0532.jpg: 640x384 5 persons, 32.1ms\n",
      "Speed: 0.5ms preprocess, 32.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0254.jpg: 640x384 4 persons, 28.5ms\n",
      "Speed: 0.5ms preprocess, 28.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0240.jpg: 640x384 4 persons, 33.7ms\n",
      "Speed: 0.5ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0526.jpg: 640x384 2 persons, 32.0ms\n",
      "Speed: 0.5ms preprocess, 32.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0485.jpg: 640x384 1 person, 31.8ms\n",
      "Speed: 0.6ms preprocess, 31.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0491.jpg: 640x384 4 persons, 35.8ms\n",
      "Speed: 0.5ms preprocess, 35.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0308.jpg: 640x384 4 persons, 32.6ms\n",
      "Speed: 0.5ms preprocess, 32.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0446.jpg: 640x384 6 persons, 32.8ms\n",
      "Speed: 0.6ms preprocess, 32.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0320.jpg: 640x384 3 persons, 31.7ms\n",
      "Speed: 0.5ms preprocess, 31.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0334.jpg: 640x384 3 persons, 34.0ms\n",
      "Speed: 0.5ms preprocess, 34.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0452.jpg: 640x384 5 persons, 38.0ms\n",
      "Speed: 0.5ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0678.jpg: 640x384 1 person, 34.4ms\n",
      "Speed: 0.5ms preprocess, 34.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0122.jpg: 640x384 8 persons, 31.1ms\n",
      "Speed: 0.6ms preprocess, 31.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0644.jpg: 640x384 1 person, 35.6ms\n",
      "Speed: 0.6ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0650.jpg: 640x384 4 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0136.jpg: 640x384 9 persons, 35.2ms\n",
      "Speed: 0.5ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0651.jpg: 640x384 3 persons, 34.7ms\n",
      "Speed: 0.5ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0137.jpg: 640x384 10 persons, 34.2ms\n",
      "Speed: 0.4ms preprocess, 34.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0123.jpg: 640x384 10 persons, 28.7ms\n",
      "Speed: 0.5ms preprocess, 28.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0645.jpg: 640x384 1 person, 29.3ms\n",
      "Speed: 0.5ms preprocess, 29.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0679.jpg: 640x384 3 persons, 32.1ms\n",
      "Speed: 0.5ms preprocess, 32.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0335.jpg: 640x384 4 persons, 30.0ms\n",
      "Speed: 0.5ms preprocess, 30.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0453.jpg: 640x384 5 persons, 30.9ms\n",
      "Speed: 0.5ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0447.jpg: 640x384 6 persons, 26.0ms\n",
      "Speed: 0.5ms preprocess, 26.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0321.jpg: 640x384 2 persons, 37.8ms\n",
      "Speed: 0.5ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0309.jpg: 640x384 2 persons, 29.5ms\n",
      "Speed: 0.5ms preprocess, 29.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0490.jpg: 640x384 2 persons, 25.6ms\n",
      "Speed: 0.5ms preprocess, 25.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0484.jpg: 640x384 2 persons, 31.6ms\n",
      "Speed: 0.4ms preprocess, 31.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0241.jpg: 640x384 5 persons, 32.1ms\n",
      "Speed: 0.5ms preprocess, 32.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0527.jpg: 640x384 1 person, 29.2ms\n",
      "Speed: 0.5ms preprocess, 29.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0533.jpg: 640x384 4 persons, 28.7ms\n",
      "Speed: 0.5ms preprocess, 28.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0255.jpg: 640x384 4 persons, 34.2ms\n",
      "Speed: 0.5ms preprocess, 34.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0269.jpg: 640x384 3 persons, 40.1ms\n",
      "Speed: 0.6ms preprocess, 40.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0282.jpg: 640x384 4 persons, 36.5ms\n",
      "Speed: 0.6ms preprocess, 36.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0296.jpg: 640x384 3 persons, 34.0ms\n",
      "Speed: 0.4ms preprocess, 34.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0043.jpg: 640x384 6 persons, 32.9ms\n",
      "Speed: 0.6ms preprocess, 32.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0057.jpg: 640x384 3 persons, 36.4ms\n",
      "Speed: 0.7ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0080.jpg: 640x384 2 persons, 35.7ms\n",
      "Speed: 0.6ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0094.jpg: 640x384 2 persons, 32.7ms\n",
      "Speed: 0.5ms preprocess, 32.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0082.jpg: 640x384 3 persons, 1 laptop, 34.4ms\n",
      "Speed: 0.5ms preprocess, 34.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0096.jpg: 640x384 3 persons, 29.6ms\n",
      "Speed: 0.5ms preprocess, 29.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0069.jpg: 640x384 4 persons, 1 tv, 35.6ms\n",
      "Speed: 0.4ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0041.jpg: 640x384 7 persons, 28.5ms\n",
      "Speed: 0.4ms preprocess, 28.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0055.jpg: 640x384 6 persons, 28.8ms\n",
      "Speed: 0.5ms preprocess, 28.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0280.jpg: 640x384 3 persons, 29.0ms\n",
      "Speed: 0.5ms preprocess, 29.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0294.jpg: 640x384 4 persons, 1 cake, 28.3ms\n",
      "Speed: 0.8ms preprocess, 28.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0519.jpg: 640x384 4 persons, 33.0ms\n",
      "Speed: 0.5ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0525.jpg: 640x384 2 persons, 1 remote, 31.7ms\n",
      "Speed: 0.6ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0243.jpg: 640x384 4 persons, 32.6ms\n",
      "Speed: 0.5ms preprocess, 32.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0257.jpg: 640x384 3 persons, 33.9ms\n",
      "Speed: 0.5ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0531.jpg: 640x384 3 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0492.jpg: 640x384 3 persons, 34.8ms\n",
      "Speed: 0.5ms preprocess, 34.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0486.jpg: 640x384 1 person, 28.7ms\n",
      "Speed: 0.6ms preprocess, 28.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0479.jpg: 640x384 3 persons, 34.3ms\n",
      "Speed: 0.6ms preprocess, 34.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0451.jpg: 640x384 5 persons, 34.9ms\n",
      "Speed: 0.5ms preprocess, 34.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0337.jpg: 640x384 3 persons, 34.1ms\n",
      "Speed: 0.5ms preprocess, 34.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0323.jpg: 640x384 3 persons, 30.9ms\n",
      "Speed: 0.6ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0445.jpg: 640x384 5 persons, 31.3ms\n",
      "Speed: 0.5ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0684.jpg: 640x384 3 persons, 34.6ms\n",
      "Speed: 0.4ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0109.jpg: 640x384 9 persons, 32.9ms\n",
      "Speed: 0.4ms preprocess, 32.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0135.jpg: 640x384 9 persons, 33.2ms\n",
      "Speed: 0.5ms preprocess, 33.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0653.jpg: 640x384 3 persons, 32.9ms\n",
      "Speed: 0.6ms preprocess, 32.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0647.jpg: 640x384 1 person, 35.5ms\n",
      "Speed: 0.5ms preprocess, 35.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0121.jpg: 640x384 8 persons, 30.3ms\n",
      "Speed: 0.5ms preprocess, 30.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0646.jpg: 640x384 1 person, 33.5ms\n",
      "Speed: 0.5ms preprocess, 33.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0120.jpg: 640x384 9 persons, 31.3ms\n",
      "Speed: 0.5ms preprocess, 31.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0134.jpg: 640x384 9 persons, 33.0ms\n",
      "Speed: 0.5ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0652.jpg: 640x384 4 persons, 32.1ms\n",
      "Speed: 0.5ms preprocess, 32.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0108.jpg: 640x384 8 persons, 29.7ms\n",
      "Speed: 0.5ms preprocess, 29.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0685.jpg: 640x384 3 persons, 31.3ms\n",
      "Speed: 0.8ms preprocess, 31.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0322.jpg: 640x384 2 persons, 34.6ms\n",
      "Speed: 0.5ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0444.jpg: 640x384 6 persons, 32.4ms\n",
      "Speed: 0.6ms preprocess, 32.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0450.jpg: 640x384 4 persons, 38.6ms\n",
      "Speed: 0.9ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0336.jpg: 640x384 3 persons, 37.9ms\n",
      "Speed: 0.7ms preprocess, 37.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0478.jpg: 640x384 3 persons, 1 book, 34.8ms\n",
      "Speed: 0.5ms preprocess, 34.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0487.jpg: 640x384 1 person, 32.9ms\n",
      "Speed: 0.5ms preprocess, 32.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0493.jpg: 640x384 3 persons, 35.4ms\n",
      "Speed: 0.5ms preprocess, 35.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0256.jpg: 640x384 4 persons, 32.4ms\n",
      "Speed: 0.6ms preprocess, 32.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0530.jpg: 640x384 3 persons, 33.2ms\n",
      "Speed: 0.4ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0524.jpg: 640x384 1 person, 1 remote, 1 cell phone, 32.7ms\n",
      "Speed: 0.5ms preprocess, 32.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0242.jpg: 640x384 4 persons, 37.0ms\n",
      "Speed: 0.5ms preprocess, 37.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0518.jpg: 640x384 4 persons, 1 cell phone, 34.5ms\n",
      "Speed: 0.6ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0295.jpg: 640x384 3 persons, 34.7ms\n",
      "Speed: 0.5ms preprocess, 34.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0281.jpg: 640x384 3 persons, 29.4ms\n",
      "Speed: 0.5ms preprocess, 29.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0054.jpg: 640x384 8 persons, 31.8ms\n",
      "Speed: 0.5ms preprocess, 31.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0040.jpg: 640x384 7 persons, 31.7ms\n",
      "Speed: 0.5ms preprocess, 31.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0068.jpg: 640x384 2 persons, 35.3ms\n",
      "Speed: 0.6ms preprocess, 35.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0097.jpg: 640x384 3 persons, 32.3ms\n",
      "Speed: 0.5ms preprocess, 32.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0083.jpg: 640x384 2 persons, 31.8ms\n",
      "Speed: 0.5ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0087.jpg: 640x384 3 persons, 33.3ms\n",
      "Speed: 0.5ms preprocess, 33.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0093.jpg: 640x384 3 persons, 34.5ms\n",
      "Speed: 0.5ms preprocess, 34.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0044.jpg: 640x384 7 persons, 30.2ms\n",
      "Speed: 0.9ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0050.jpg: 640x384 4 persons, 1 cell phone, 35.6ms\n",
      "Speed: 0.7ms preprocess, 35.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0078.jpg: 640x384 3 persons, 29.3ms\n",
      "Speed: 0.6ms preprocess, 29.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0285.jpg: 640x384 3 persons, 35.3ms\n",
      "Speed: 0.5ms preprocess, 35.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0291.jpg: 640x384 5 persons, 1 cake, 32.8ms\n",
      "Speed: 0.6ms preprocess, 32.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0246.jpg: 640x384 5 persons, 31.5ms\n",
      "Speed: 0.5ms preprocess, 31.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0520.jpg: 640x384 3 persons, 29.4ms\n",
      "Speed: 0.5ms preprocess, 29.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0534.jpg: 640x384 2 persons, 29.3ms\n",
      "Speed: 0.5ms preprocess, 29.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0252.jpg: 640x384 3 persons, 31.3ms\n",
      "Speed: 0.5ms preprocess, 31.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0508.jpg: 640x384 3 persons, 28.6ms\n",
      "Speed: 0.4ms preprocess, 28.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0497.jpg: 640x384 2 persons, 1 tv, 33.6ms\n",
      "Speed: 0.5ms preprocess, 33.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0483.jpg: 640x384 1 person, 33.7ms\n",
      "Speed: 0.5ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0332.jpg: 640x384 3 persons, 32.3ms\n",
      "Speed: 0.7ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0454.jpg: 640x384 3 persons, 34.3ms\n",
      "Speed: 1.0ms preprocess, 34.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0440.jpg: 640x384 7 persons, 34.6ms\n",
      "Speed: 0.5ms preprocess, 34.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0326.jpg: 640x384 3 persons, 34.1ms\n",
      "Speed: 0.7ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0468.jpg: 640x384 2 persons, 33.7ms\n",
      "Speed: 0.5ms preprocess, 33.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0681.jpg: 640x384 2 persons, 36.4ms\n",
      "Speed: 0.5ms preprocess, 36.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0656.jpg: 640x384 3 persons, 27.0ms\n",
      "Speed: 0.5ms preprocess, 27.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0130.jpg: 640x384 8 persons, 31.4ms\n",
      "Speed: 0.5ms preprocess, 31.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0124.jpg: 640x384 9 persons, 32.8ms\n",
      "Speed: 0.5ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0642.jpg: 640x384 1 person, 30.4ms\n",
      "Speed: 0.5ms preprocess, 30.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0118.jpg: 640x384 9 persons, 34.4ms\n",
      "Speed: 0.5ms preprocess, 34.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0119.jpg: 640x384 9 persons, 34.8ms\n",
      "Speed: 0.4ms preprocess, 34.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0125.jpg: 640x384 9 persons, 1 tie, 36.9ms\n",
      "Speed: 0.5ms preprocess, 36.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0643.jpg: 640x384 1 person, 30.9ms\n",
      "Speed: 0.4ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0657.jpg: 640x384 4 persons, 31.3ms\n",
      "Speed: 0.5ms preprocess, 31.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0131.jpg: 640x384 8 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0680.jpg: 640x384 3 persons, 34.4ms\n",
      "Speed: 0.4ms preprocess, 34.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0469.jpg: 640x384 4 persons, 40.3ms\n",
      "Speed: 0.5ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0441.jpg: 640x384 6 persons, 37.8ms\n",
      "Speed: 0.7ms preprocess, 37.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0327.jpg: 640x384 4 persons, 39.5ms\n",
      "Speed: 0.5ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0333.jpg: 640x384 3 persons, 38.2ms\n",
      "Speed: 0.6ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0455.jpg: 640x384 4 persons, 42.6ms\n",
      "Speed: 0.6ms preprocess, 42.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0482.jpg: 640x384 1 person, 38.9ms\n",
      "Speed: 0.5ms preprocess, 38.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0496.jpg: 640x384 1 person, 1 tv, 38.1ms\n",
      "Speed: 0.5ms preprocess, 38.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0509.jpg: 640x384 2 persons, 35.7ms\n",
      "Speed: 0.5ms preprocess, 35.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0535.jpg: 640x384 2 persons, 1 cell phone, 36.5ms\n",
      "Speed: 0.5ms preprocess, 36.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0253.jpg: 640x384 2 persons, 32.6ms\n",
      "Speed: 0.5ms preprocess, 32.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0247.jpg: 640x384 3 persons, 31.0ms\n",
      "Speed: 0.5ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0521.jpg: 640x384 2 persons, 1 remote, 30.1ms\n",
      "Speed: 0.5ms preprocess, 30.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0290.jpg: 640x384 5 persons, 29.0ms\n",
      "Speed: 0.6ms preprocess, 29.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0284.jpg: 640x384 4 persons, 30.6ms\n",
      "Speed: 0.5ms preprocess, 30.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0079.jpg: 640x384 4 persons, 33.2ms\n",
      "Speed: 0.6ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0051.jpg: 640x384 5 persons, 31.3ms\n",
      "Speed: 0.5ms preprocess, 31.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0045.jpg: 640x384 4 persons, 33.5ms\n",
      "Speed: 0.5ms preprocess, 33.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0092.jpg: 640x384 2 persons, 34.4ms\n",
      "Speed: 0.5ms preprocess, 34.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0086.jpg: 640x384 2 persons, 34.2ms\n",
      "Speed: 0.6ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0090.jpg: 640x384 (no detections), 32.0ms\n",
      "Speed: 0.6ms preprocess, 32.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0084.jpg: 640x384 2 persons, 1 tv, 34.4ms\n",
      "Speed: 0.5ms preprocess, 34.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0053.jpg: 640x384 3 persons, 1 cell phone, 35.3ms\n",
      "Speed: 1.0ms preprocess, 35.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0047.jpg: 640x384 5 persons, 31.8ms\n",
      "Speed: 0.5ms preprocess, 31.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0292.jpg: 640x384 4 persons, 31.9ms\n",
      "Speed: 0.5ms preprocess, 31.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0286.jpg: 640x384 2 persons, 33.9ms\n",
      "Speed: 0.6ms preprocess, 33.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0251.jpg: 640x384 3 persons, 34.8ms\n",
      "Speed: 0.5ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0537.jpg: 640x384 4 persons, 28.4ms\n",
      "Speed: 0.6ms preprocess, 28.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0523.jpg: 640x384 2 persons, 29.7ms\n",
      "Speed: 0.5ms preprocess, 29.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0245.jpg: 640x384 4 persons, 32.0ms\n",
      "Speed: 0.5ms preprocess, 32.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0279.jpg: 640x384 7 persons, 32.7ms\n",
      "Speed: 0.5ms preprocess, 32.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0480.jpg: 640x384 1 person, 1 book, 31.0ms\n",
      "Speed: 0.5ms preprocess, 31.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0494.jpg: 640x384 2 persons, 1 tv, 31.7ms\n",
      "Speed: 0.5ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0325.jpg: 640x384 3 persons, 33.1ms\n",
      "Speed: 0.5ms preprocess, 33.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0443.jpg: 640x384 7 persons, 37.7ms\n",
      "Speed: 0.4ms preprocess, 37.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0457.jpg: 640x384 2 persons, 30.7ms\n",
      "Speed: 0.7ms preprocess, 30.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0331.jpg: 640x384 2 persons, 28.0ms\n",
      "Speed: 0.6ms preprocess, 28.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0319.jpg: 640x384 3 persons, 34.2ms\n",
      "Speed: 0.5ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0682.jpg: 640x384 3 persons, 33.0ms\n",
      "Speed: 0.4ms preprocess, 33.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0641.jpg: 640x384 1 person, 28.8ms\n",
      "Speed: 0.5ms preprocess, 28.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0127.jpg: 640x384 10 persons, 31.4ms\n",
      "Speed: 0.6ms preprocess, 31.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0133.jpg: 640x384 8 persons, 31.9ms\n",
      "Speed: 0.4ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0655.jpg: 640x384 4 persons, 33.7ms\n",
      "Speed: 0.5ms preprocess, 33.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0669.jpg: 640x384 (no detections), 29.4ms\n",
      "Speed: 0.5ms preprocess, 29.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0668.jpg: 640x384 (no detections), 30.6ms\n",
      "Speed: 0.8ms preprocess, 30.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0132.jpg: 640x384 9 persons, 33.9ms\n",
      "Speed: 0.6ms preprocess, 33.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0654.jpg: 640x384 2 persons, 33.8ms\n",
      "Speed: 0.5ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0640.jpg: 640x384 1 person, 30.2ms\n",
      "Speed: 0.5ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0126.jpg: 640x384 10 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0683.jpg: 640x384 2 persons, 31.0ms\n",
      "Speed: 0.5ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0318.jpg: 640x384 2 persons, 30.9ms\n",
      "Speed: 0.5ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0456.jpg: 640x384 3 persons, 34.0ms\n",
      "Speed: 0.5ms preprocess, 34.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0330.jpg: 640x384 3 persons, 29.7ms\n",
      "Speed: 0.6ms preprocess, 29.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0324.jpg: 640x384 4 persons, 32.5ms\n",
      "Speed: 0.5ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0442.jpg: 640x384 5 persons, 34.2ms\n",
      "Speed: 0.6ms preprocess, 34.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0495.jpg: 640x384 4 persons, 31.5ms\n",
      "Speed: 0.5ms preprocess, 31.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0481.jpg: 640x384 2 persons, 32.2ms\n",
      "Speed: 0.6ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0278.jpg: 640x384 3 persons, 28.5ms\n",
      "Speed: 0.5ms preprocess, 28.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0522.jpg: 640x384 2 persons, 1 cell phone, 34.9ms\n",
      "Speed: 0.5ms preprocess, 34.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0244.jpg: 640x384 3 persons, 40.2ms\n",
      "Speed: 0.5ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0250.jpg: 640x384 3 persons, 34.4ms\n",
      "Speed: 0.5ms preprocess, 34.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0536.jpg: 640x384 3 persons, 32.9ms\n",
      "Speed: 0.6ms preprocess, 32.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0287.jpg: 640x384 2 persons, 32.3ms\n",
      "Speed: 0.4ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0293.jpg: 640x384 3 persons, 28.8ms\n",
      "Speed: 0.7ms preprocess, 28.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0046.jpg: 640x384 7 persons, 28.6ms\n",
      "Speed: 0.6ms preprocess, 28.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0052.jpg: 640x384 4 persons, 35.5ms\n",
      "Speed: 0.5ms preprocess, 35.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0085.jpg: 640x384 2 persons, 32.1ms\n",
      "Speed: 0.5ms preprocess, 32.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0091.jpg: 640x384 (no detections), 37.6ms\n",
      "Speed: 0.5ms preprocess, 37.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0009.jpg: 640x384 6 persons, 29.4ms\n",
      "Speed: 0.6ms preprocess, 29.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0035.jpg: 640x384 4 persons, 31.1ms\n",
      "Speed: 0.6ms preprocess, 31.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0021.jpg: 640x384 5 persons, 32.2ms\n",
      "Speed: 0.5ms preprocess, 32.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0592.jpg: 640x384 3 persons, 35.9ms\n",
      "Speed: 0.5ms preprocess, 35.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0586.jpg: 640x384 6 persons, 33.9ms\n",
      "Speed: 0.6ms preprocess, 33.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0579.jpg: 640x384 5 persons, 35.1ms\n",
      "Speed: 0.6ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0237.jpg: 640x384 7 persons, 34.2ms\n",
      "Speed: 0.5ms preprocess, 34.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0551.jpg: 640x384 4 persons, 37.4ms\n",
      "Speed: 0.5ms preprocess, 37.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0545.jpg: 640x384 4 persons, 31.2ms\n",
      "Speed: 0.5ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0223.jpg: 640x384 6 persons, 30.8ms\n",
      "Speed: 0.6ms preprocess, 30.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0380.jpg: 640x384 5 persons, 34.7ms\n",
      "Speed: 0.5ms preprocess, 34.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0394.jpg: 640x384 4 persons, 28.2ms\n",
      "Speed: 0.6ms preprocess, 28.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0419.jpg: 640x384 5 persons, 27.8ms\n",
      "Speed: 0.5ms preprocess, 27.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0343.jpg: 640x384 2 persons, 30.2ms\n",
      "Speed: 0.6ms preprocess, 30.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0425.jpg: 640x384 5 persons, 30.0ms\n",
      "Speed: 0.5ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0431.jpg: 640x384 6 persons, 32.9ms\n",
      "Speed: 0.4ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0357.jpg: 640x384 1 person, 32.5ms\n",
      "Speed: 0.5ms preprocess, 32.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0182.jpg: 640x384 3 persons, 30.9ms\n",
      "Speed: 0.5ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0196.jpg: 640x384 6 persons, 30.9ms\n",
      "Speed: 0.5ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0169.jpg: 640x384 3 persons, 31.8ms\n",
      "Speed: 0.5ms preprocess, 31.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0627.jpg: 640x384 3 persons, 31.5ms\n",
      "Speed: 0.5ms preprocess, 31.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0141.jpg: 640x384 8 persons, 29.7ms\n",
      "Speed: 0.4ms preprocess, 29.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0155.jpg: 640x384 3 persons, 33.3ms\n",
      "Speed: 0.5ms preprocess, 33.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0633.jpg: 640x384 2 persons, 28.2ms\n",
      "Speed: 0.5ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0154.jpg: 640x384 5 persons, 34.1ms\n",
      "Speed: 0.5ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0632.jpg: 640x384 1 person, 33.4ms\n",
      "Speed: 0.4ms preprocess, 33.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0626.jpg: 640x384 1 person, 31.9ms\n",
      "Speed: 0.5ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0140.jpg: 640x384 9 persons, 29.8ms\n",
      "Speed: 0.5ms preprocess, 29.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0168.jpg: 640x384 4 persons, 30.0ms\n",
      "Speed: 0.8ms preprocess, 30.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0197.jpg: 640x384 4 persons, 32.3ms\n",
      "Speed: 0.4ms preprocess, 32.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0183.jpg: 640x384 3 persons, 29.6ms\n",
      "Speed: 0.4ms preprocess, 29.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0430.jpg: 640x384 6 persons, 30.8ms\n",
      "Speed: 0.5ms preprocess, 30.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0356.jpg: 640x384 2 persons, 1 cow, 33.6ms\n",
      "Speed: 0.6ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0342.jpg: 640x384 3 persons, 1 bicycle, 32.9ms\n",
      "Speed: 0.5ms preprocess, 32.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0424.jpg: 640x384 5 persons, 31.8ms\n",
      "Speed: 0.5ms preprocess, 31.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0418.jpg: 640x384 5 persons, 30.1ms\n",
      "Speed: 0.4ms preprocess, 30.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0395.jpg: 640x384 2 persons, 34.3ms\n",
      "Speed: 1.0ms preprocess, 34.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0381.jpg: 640x384 4 persons, 35.1ms\n",
      "Speed: 0.6ms preprocess, 35.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0544.jpg: 640x384 6 persons, 37.7ms\n",
      "Speed: 0.7ms preprocess, 37.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0222.jpg: 640x384 6 persons, 29.3ms\n",
      "Speed: 0.5ms preprocess, 29.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0236.jpg: 640x384 8 persons, 32.5ms\n",
      "Speed: 0.6ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0550.jpg: 640x384 5 persons, 31.5ms\n",
      "Speed: 0.7ms preprocess, 31.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0578.jpg: 640x384 6 persons, 31.7ms\n",
      "Speed: 0.5ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0587.jpg: 640x384 6 persons, 31.3ms\n",
      "Speed: 0.7ms preprocess, 31.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0593.jpg: 640x384 5 persons, 32.0ms\n",
      "Speed: 0.5ms preprocess, 32.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0020.jpg: 640x384 5 persons, 27.6ms\n",
      "Speed: 0.6ms preprocess, 27.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0034.jpg: 640x384 6 persons, 38.5ms\n",
      "Speed: 0.6ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0008.jpg: 640x384 6 persons, 33.2ms\n",
      "Speed: 0.5ms preprocess, 33.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0022.jpg: 640x384 5 persons, 32.6ms\n",
      "Speed: 0.5ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0036.jpg: 640x384 5 persons, 32.4ms\n",
      "Speed: 0.7ms preprocess, 32.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0585.jpg: 640x384 5 persons, 31.3ms\n",
      "Speed: 0.5ms preprocess, 31.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0591.jpg: 640x384 4 persons, 32.7ms\n",
      "Speed: 0.6ms preprocess, 32.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0208.jpg: 640x384 6 persons, 29.1ms\n",
      "Speed: 0.5ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0220.jpg: 640x384 6 persons, 35.4ms\n",
      "Speed: 0.5ms preprocess, 35.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0546.jpg: 640x384 3 persons, 1 snowboard, 32.2ms\n",
      "Speed: 0.5ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0552.jpg: 640x384 3 persons, 35.2ms\n",
      "Speed: 0.5ms preprocess, 35.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0234.jpg: 640x384 6 persons, 34.2ms\n",
      "Speed: 0.5ms preprocess, 34.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0397.jpg: 640x384 2 persons, 33.2ms\n",
      "Speed: 0.5ms preprocess, 33.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0383.jpg: 640x384 4 persons, 1 scissors, 33.3ms\n",
      "Speed: 0.5ms preprocess, 33.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0368.jpg: 640x384 1 person, 30.6ms\n",
      "Speed: 0.5ms preprocess, 30.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0354.jpg: 640x384 2 persons, 31.7ms\n",
      "Speed: 0.5ms preprocess, 31.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0432.jpg: 640x384 5 persons, 31.8ms\n",
      "Speed: 0.4ms preprocess, 31.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0426.jpg: 640x384 5 persons, 29.5ms\n",
      "Speed: 0.6ms preprocess, 29.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0340.jpg: 640x384 2 persons, 33.3ms\n",
      "Speed: 0.5ms preprocess, 33.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0195.jpg: 640x384 6 persons, 34.6ms\n",
      "Speed: 0.5ms preprocess, 34.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0181.jpg: 640x384 3 persons, 27.9ms\n",
      "Speed: 0.5ms preprocess, 27.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0618.jpg: 640x384 1 person, 29.9ms\n",
      "Speed: 0.5ms preprocess, 29.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0630.jpg: 640x384 (no detections), 36.3ms\n",
      "Speed: 0.4ms preprocess, 36.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0156.jpg: 640x384 3 persons, 30.9ms\n",
      "Speed: 0.6ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0142.jpg: 640x384 9 persons, 28.7ms\n",
      "Speed: 0.5ms preprocess, 28.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0624.jpg: 640x384 1 person, 31.7ms\n",
      "Speed: 0.5ms preprocess, 31.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0143.jpg: 640x384 7 persons, 29.3ms\n",
      "Speed: 0.5ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0625.jpg: 640x384 2 persons, 36.5ms\n",
      "Speed: 0.6ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0631.jpg: 640x384 1 person, 33.1ms\n",
      "Speed: 0.5ms preprocess, 33.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0157.jpg: 640x384 3 persons, 33.0ms\n",
      "Speed: 0.5ms preprocess, 33.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0619.jpg: 640x384 1 person, 34.0ms\n",
      "Speed: 0.5ms preprocess, 34.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0180.jpg: 640x384 3 persons, 30.7ms\n",
      "Speed: 0.5ms preprocess, 30.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0194.jpg: 640x384 5 persons, 32.5ms\n",
      "Speed: 0.5ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0427.jpg: 640x384 3 persons, 30.4ms\n",
      "Speed: 0.4ms preprocess, 30.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0341.jpg: 640x384 2 persons, 1 bicycle, 32.5ms\n",
      "Speed: 0.5ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0355.jpg: 640x384 3 persons, 28.6ms\n",
      "Speed: 0.5ms preprocess, 28.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0433.jpg: 640x384 4 persons, 32.3ms\n",
      "Speed: 0.9ms preprocess, 32.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0369.jpg: 640x384 2 persons, 31.2ms\n",
      "Speed: 0.5ms preprocess, 31.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0382.jpg: 640x384 6 persons, 36.2ms\n",
      "Speed: 0.5ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0396.jpg: 640x384 2 persons, 31.3ms\n",
      "Speed: 0.5ms preprocess, 31.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0553.jpg: 640x384 4 persons, 31.2ms\n",
      "Speed: 0.6ms preprocess, 31.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0235.jpg: 640x384 4 persons, 30.0ms\n",
      "Speed: 0.5ms preprocess, 30.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0221.jpg: 640x384 8 persons, 26.0ms\n",
      "Speed: 0.5ms preprocess, 26.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0547.jpg: 640x384 5 persons, 30.6ms\n",
      "Speed: 0.5ms preprocess, 30.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0209.jpg: 640x384 5 persons, 33.0ms\n",
      "Speed: 0.5ms preprocess, 33.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0590.jpg: 640x384 5 persons, 31.3ms\n",
      "Speed: 0.5ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0584.jpg: 640x384 7 persons, 36.1ms\n",
      "Speed: 0.5ms preprocess, 36.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0037.jpg: 640x384 6 persons, 30.8ms\n",
      "Speed: 0.5ms preprocess, 30.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0023.jpg: 640x384 5 persons, 31.4ms\n",
      "Speed: 0.5ms preprocess, 31.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0027.jpg: 640x384 4 persons, 33.2ms\n",
      "Speed: 0.5ms preprocess, 33.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0033.jpg: 640x384 6 persons, 31.4ms\n",
      "Speed: 0.5ms preprocess, 31.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0580.jpg: 640x384 5 persons, 32.5ms\n",
      "Speed: 0.4ms preprocess, 32.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0594.jpg: 640x384 4 persons, 1 cell phone, 29.6ms\n",
      "Speed: 0.4ms preprocess, 29.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0543.jpg: 640x384 4 persons, 29.8ms\n",
      "Speed: 0.5ms preprocess, 29.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0225.jpg: 640x384 6 persons, 30.0ms\n",
      "Speed: 0.4ms preprocess, 30.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0231.jpg: 640x384 6 persons, 32.7ms\n",
      "Speed: 0.5ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0557.jpg: 640x384 6 persons, 29.6ms\n",
      "Speed: 0.5ms preprocess, 29.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0219.jpg: 640x384 6 persons, 28.0ms\n",
      "Speed: 0.5ms preprocess, 28.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0392.jpg: 640x384 3 persons, 33.4ms\n",
      "Speed: 0.5ms preprocess, 33.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0386.jpg: 640x384 5 persons, 31.2ms\n",
      "Speed: 0.4ms preprocess, 31.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0437.jpg: 640x384 5 persons, 30.6ms\n",
      "Speed: 0.5ms preprocess, 30.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0351.jpg: 640x384 2 persons, 32.9ms\n",
      "Speed: 0.5ms preprocess, 32.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0345.jpg: 640x384 4 persons, 31.3ms\n",
      "Speed: 0.5ms preprocess, 31.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0423.jpg: 640x384 6 persons, 32.1ms\n",
      "Speed: 0.4ms preprocess, 32.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0379.jpg: 640x384 3 persons, 1 skateboard, 27.7ms\n",
      "Speed: 0.6ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0190.jpg: 640x384 6 persons, 32.3ms\n",
      "Speed: 0.5ms preprocess, 32.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0184.jpg: 640x384 4 persons, 31.4ms\n",
      "Speed: 0.4ms preprocess, 31.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0153.jpg: 640x384 7 persons, 28.3ms\n",
      "Speed: 0.5ms preprocess, 28.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0635.jpg: 640x384 2 persons, 31.3ms\n",
      "Speed: 0.5ms preprocess, 31.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0621.jpg: 640x384 3 persons, 32.1ms\n",
      "Speed: 0.5ms preprocess, 32.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0147.jpg: 640x384 6 persons, 30.0ms\n",
      "Speed: 0.5ms preprocess, 30.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0609.jpg: 640x384 3 persons, 32.0ms\n",
      "Speed: 0.5ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0608.jpg: 640x384 3 persons, 31.1ms\n",
      "Speed: 0.4ms preprocess, 31.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0620.jpg: 640x384 2 persons, 29.5ms\n",
      "Speed: 0.5ms preprocess, 29.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0146.jpg: 640x384 6 persons, 31.0ms\n",
      "Speed: 0.5ms preprocess, 31.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0152.jpg: 640x384 6 persons, 33.5ms\n",
      "Speed: 0.4ms preprocess, 33.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0634.jpg: 640x384 3 persons, 1 sports ball, 27.9ms\n",
      "Speed: 0.4ms preprocess, 27.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0185.jpg: 640x384 3 persons, 31.0ms\n",
      "Speed: 0.5ms preprocess, 31.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0191.jpg: 640x384 5 persons, 27.5ms\n",
      "Speed: 0.5ms preprocess, 27.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0378.jpg: 640x384 4 persons, 27.7ms\n",
      "Speed: 0.5ms preprocess, 27.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0344.jpg: 640x384 2 persons, 29.0ms\n",
      "Speed: 0.5ms preprocess, 29.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0422.jpg: 640x384 6 persons, 34.0ms\n",
      "Speed: 0.5ms preprocess, 34.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0436.jpg: 640x384 4 persons, 34.1ms\n",
      "Speed: 0.5ms preprocess, 34.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0350.jpg: 640x384 2 persons, 27.5ms\n",
      "Speed: 0.5ms preprocess, 27.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0387.jpg: 640x384 6 persons, 34.7ms\n",
      "Speed: 0.5ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0393.jpg: 640x384 4 persons, 31.8ms\n",
      "Speed: 0.5ms preprocess, 31.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0218.jpg: 640x384 6 persons, 30.2ms\n",
      "Speed: 0.8ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0230.jpg: 640x384 6 persons, 34.1ms\n",
      "Speed: 0.5ms preprocess, 34.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0556.jpg: 640x384 6 persons, 31.6ms\n",
      "Speed: 0.5ms preprocess, 31.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0542.jpg: 640x384 4 persons, 34.2ms\n",
      "Speed: 0.5ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0224.jpg: 640x384 5 persons, 32.5ms\n",
      "Speed: 0.5ms preprocess, 32.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0595.jpg: 640x384 4 persons, 31.2ms\n",
      "Speed: 0.4ms preprocess, 31.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0581.jpg: 640x384 5 persons, 30.3ms\n",
      "Speed: 0.5ms preprocess, 30.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0032.jpg: 640x384 5 persons, 33.3ms\n",
      "Speed: 0.5ms preprocess, 33.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0026.jpg: 640x384 4 persons, 35.0ms\n",
      "Speed: 0.5ms preprocess, 35.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0030.jpg: 640x384 5 persons, 31.9ms\n",
      "Speed: 0.5ms preprocess, 31.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0024.jpg: 640x384 5 persons, 29.8ms\n",
      "Speed: 0.5ms preprocess, 29.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0018.jpg: 640x384 5 persons, 32.6ms\n",
      "Speed: 0.5ms preprocess, 32.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0597.jpg: 640x384 3 persons, 34.0ms\n",
      "Speed: 0.5ms preprocess, 34.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0583.jpg: 640x384 5 persons, 27.8ms\n",
      "Speed: 0.6ms preprocess, 27.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0554.jpg: 640x384 3 persons, 32.7ms\n",
      "Speed: 0.7ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0232.jpg: 640x384 4 persons, 30.2ms\n",
      "Speed: 0.5ms preprocess, 30.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0226.jpg: 640x384 6 persons, 31.3ms\n",
      "Speed: 0.5ms preprocess, 31.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0540.jpg: 640x384 4 persons, 30.3ms\n",
      "Speed: 0.6ms preprocess, 30.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0568.jpg: 640x384 6 persons, 31.1ms\n",
      "Speed: 0.5ms preprocess, 31.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0385.jpg: 640x384 2 persons, 28.3ms\n",
      "Speed: 0.5ms preprocess, 28.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0391.jpg: 640x384 5 persons, 30.6ms\n",
      "Speed: 0.5ms preprocess, 30.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0420.jpg: 640x384 5 persons, 30.9ms\n",
      "Speed: 0.7ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0346.jpg: 640x384 6 persons, 29.3ms\n",
      "Speed: 0.4ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0352.jpg: 640x384 2 persons, 36.2ms\n",
      "Speed: 0.5ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0434.jpg: 640x384 5 persons, 33.9ms\n",
      "Speed: 0.5ms preprocess, 33.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0408.jpg: 640x384 7 persons, 33.1ms\n",
      "Speed: 0.5ms preprocess, 33.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0187.jpg: 640x384 5 persons, 35.2ms\n",
      "Speed: 0.5ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0193.jpg: 640x384 5 persons, 30.6ms\n",
      "Speed: 0.5ms preprocess, 30.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0144.jpg: 640x384 7 persons, 29.8ms\n",
      "Speed: 0.5ms preprocess, 29.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0622.jpg: 640x384 2 persons, 31.9ms\n",
      "Speed: 0.6ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0636.jpg: 640x384 2 persons, 30.1ms\n",
      "Speed: 0.5ms preprocess, 30.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0150.jpg: 640x384 5 persons, 32.4ms\n",
      "Speed: 0.5ms preprocess, 32.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0178.jpg: 640x384 3 persons, 32.2ms\n",
      "Speed: 0.5ms preprocess, 32.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0179.jpg: 640x384 3 persons, 28.5ms\n",
      "Speed: 0.5ms preprocess, 28.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0637.jpg: 640x384 3 persons, 30.1ms\n",
      "Speed: 0.5ms preprocess, 30.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0151.jpg: 640x384 6 persons, 35.5ms\n",
      "Speed: 0.6ms preprocess, 35.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0145.jpg: 640x384 6 persons, 36.7ms\n",
      "Speed: 0.6ms preprocess, 36.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0623.jpg: 640x384 1 person, 32.2ms\n",
      "Speed: 0.5ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0192.jpg: 640x384 4 persons, 31.9ms\n",
      "Speed: 0.5ms preprocess, 31.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0186.jpg: 640x384 5 persons, 37.1ms\n",
      "Speed: 0.6ms preprocess, 37.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0409.jpg: 640x384 5 persons, 30.6ms\n",
      "Speed: 0.4ms preprocess, 30.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0353.jpg: 640x384 2 persons, 33.6ms\n",
      "Speed: 0.6ms preprocess, 33.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0435.jpg: 640x384 4 persons, 30.5ms\n",
      "Speed: 0.4ms preprocess, 30.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0421.jpg: 640x384 6 persons, 29.1ms\n",
      "Speed: 0.5ms preprocess, 29.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0347.jpg: 640x384 4 persons, 31.9ms\n",
      "Speed: 0.6ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0390.jpg: 640x384 4 persons, 29.4ms\n",
      "Speed: 0.6ms preprocess, 29.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0384.jpg: 640x384 5 persons, 34.4ms\n",
      "Speed: 0.4ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0569.jpg: 640x384 6 persons, 1 cell phone, 30.3ms\n",
      "Speed: 0.6ms preprocess, 30.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0227.jpg: 640x384 5 persons, 34.6ms\n",
      "Speed: 0.5ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0541.jpg: 640x384 4 persons, 34.3ms\n",
      "Speed: 0.5ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0555.jpg: 640x384 4 persons, 33.1ms\n",
      "Speed: 0.5ms preprocess, 33.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0233.jpg: 640x384 5 persons, 30.9ms\n",
      "Speed: 0.6ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0582.jpg: 640x384 5 persons, 40.2ms\n",
      "Speed: 0.5ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0596.jpg: 640x384 4 persons, 31.9ms\n",
      "Speed: 0.5ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0019.jpg: 640x384 4 persons, 34.7ms\n",
      "Speed: 0.5ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0025.jpg: 640x384 5 persons, 32.7ms\n",
      "Speed: 0.5ms preprocess, 32.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference/frames/frame_0031.jpg: 640x384 5 persons, 31.5ms\n",
      "Speed: 0.5ms preprocess, 31.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")  # pretrained YOLO8n model\n",
    "\n",
    "# \"frames\" 디렉토리 안에 있는 파일과 폴더 목록을 가져옴\n",
    "frames = os.listdir(\"frames/\")\n",
    "\n",
    "# 원하는 디렉토리 경로 설정\n",
    "directory_path = \"results\"\n",
    "\n",
    "# 디렉토리가 없으면 생성\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "    print(f\"디렉토리 '{directory_path}'가 생성되었어.\")\n",
    "else:\n",
    "    print(f\"디렉토리 '{directory_path}'가 이미 존재해.\")\n",
    "\n",
    "for frame in frames:\n",
    "    # YOLOv8 모델을 사용하여 객체 감지 수행\n",
    "    results = model(\"frames/\" + frame)  # , device=\"mps\" (맥북)\n",
    "\n",
    "    # Process results list\n",
    "    for result in results:\n",
    "        result.save(filename=\"results/\" + frame)  # save to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 프레임을 동영상으로 변환 - moviepy 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이미지 파일들이 저장된 디렉토리 경로\n",
    "# image_folder = \"results\"  # 이미지 파일들이 있는 폴더 경로\n",
    "# fps = int(fps)  # 초당 프레임 수 설정\n",
    "\n",
    "# # 이미지 파일 리스트 가져오기 (예: jpg, png 형식)\n",
    "# image_files = [\n",
    "#     os.path.join(image_folder, img)\n",
    "#     for img in sorted(os.listdir(image_folder))\n",
    "#     if img.endswith((\".jpg\", \".png\"))\n",
    "# ]\n",
    "\n",
    "# # 이미지 시퀀스를 이용해 클립 생성\n",
    "# clip = ImageSequenceClip(image_files, fps=fps)\n",
    "\n",
    "# # 동영상 파일로 저장\n",
    "# output_path = \"output_video.mp4\"\n",
    "# clip.write_videofile(output_path, codec=\"libx264\")\n",
    "\n",
    "# print(f\"동영상이 생성되었습니다: {output_path}\")\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# 이미지들이 저장된 폴더 경로와 저장할 비디오 파일 이름 설정\n",
    "image_folder = 'results'  # 이미지들이 저장된 폴더 경로\n",
    "video_name = 'output_video.mp4'  # 저장할 비디오 파일 이름\n",
    "\n",
    "# 이미지 파일 이름을 읽고 정렬 (순서대로 동영상을 만들기 위해)\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\") or img.endswith(\".jpg\")]\n",
    "images.sort()\n",
    "\n",
    "# 첫 번째 이미지에서 프레임의 너비와 높이 가져오기\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "# 비디오 코덱과 파일명 설정, FPS 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # mp4 코덱 설정\n",
    "video = cv2.VideoWriter(video_name, fourcc, 30, (width, height))  # FPS를 30으로 설정\n",
    "\n",
    "# 이미지를 순차적으로 불러와서 비디오에 추가\n",
    "for image in images:\n",
    "    frame = cv2.imread(os.path.join(image_folder, image))\n",
    "    video.write(frame)\n",
    "\n",
    "# 비디오 파일 저장 종료\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/yunganglog/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 158, in _start_notebook\n",
      "\u001b[1;31m    from notebook import notebookapp as app\n",
      "\u001b[1;31mImportError: cannot import name 'notebookapp' from 'notebook' (/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/notebook/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/yunganglog/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/daemon/daemon_python.py\", line 54, in _decorator\n",
      "\u001b[1;31m    return func(self, *args, **kwargs)\n",
      "\u001b[1;31m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;31m  File \"/Users/yunganglog/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 111, in m_exec_module_observable\n",
      "\u001b[1;31m    self._start_notebook(args, cwd, env)\n",
      "\u001b[1;31m  File \"/Users/yunganglog/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 160, in _start_notebook\n",
      "\u001b[1;31m    from notebook import app as app\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/notebook/app.py\", line 17, in <module>\n",
      "\u001b[1;31m    from jupyter_server.serverapp import flags\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jupyter_server/serverapp.py\", line 39, in <module>\n",
      "\u001b[1;31m    from jupyter_events.logger import EventLogger\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jupyter_events/__init__.py\", line 3, in <module>\n",
      "\u001b[1;31m    from .logger import EVENTS_METADATA_VERSION, EventLogger\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jupyter_events/logger.py\", line 14, in <module>\n",
      "\u001b[1;31m    from jsonschema import ValidationError\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jsonschema/__init__.py\", line 13, in <module>\n",
      "\u001b[1;31m    from jsonschema._format import FormatChecker\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jsonschema/_format.py\", line 11, in <module>\n",
      "\u001b[1;31m    from jsonschema.exceptions import FormatError\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jsonschema/exceptions.py\", line 15, in <module>\n",
      "\u001b[1;31m    from referencing.exceptions import Unresolvable as _Unresolvable\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/referencing/__init__.py\", line 5, in <module>\n",
      "\u001b[1;31m    from referencing._core import Anchor, Registry, Resource, Specification\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/referencing/_core.py\", line 9, in <module>\n",
      "\u001b[1;31m    from rpds import HashTrieMap, HashTrieSet, List\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/rpds/__init__.py\", line 1, in <module>\n",
      "\u001b[1;31m    from .rpds import *\n",
      "\u001b[1;31mImportError: dlopen(/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/rpds/rpds.cpython-311-darwin.so, 0x0002): tried: '/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/rpds/rpds.cpython-311-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/rpds/rpds.cpython-311-darwin.so' (no such file), '/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/rpds/rpds.cpython-311-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64'))\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mFailed to run jupyter as observable with args notebook --no-browser --notebook-dir=\"/Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference\" --config=/var/folders/xg/ll2c686j3hq46hd560c95dhh0000gn/T/bef2a538-84bb-4242-b99b-2efe575ae8d3/jupyter_notebook_config.py --NotebookApp.iopub_data_rate_limit=10000000000.0. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from moviepy.editor import ImageSequenceClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/yunganglog/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 158, in _start_notebook\n",
      "\u001b[1;31m    from notebook import notebookapp as app\n",
      "\u001b[1;31mImportError: cannot import name 'notebookapp' from 'notebook' (/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/notebook/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/yunganglog/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/daemon/daemon_python.py\", line 54, in _decorator\n",
      "\u001b[1;31m    return func(self, *args, **kwargs)\n",
      "\u001b[1;31m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;31m  File \"/Users/yunganglog/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 111, in m_exec_module_observable\n",
      "\u001b[1;31m    self._start_notebook(args, cwd, env)\n",
      "\u001b[1;31m  File \"/Users/yunganglog/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 160, in _start_notebook\n",
      "\u001b[1;31m    from notebook import app as app\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/notebook/app.py\", line 17, in <module>\n",
      "\u001b[1;31m    from jupyter_server.serverapp import flags\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jupyter_server/serverapp.py\", line 39, in <module>\n",
      "\u001b[1;31m    from jupyter_events.logger import EventLogger\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jupyter_events/__init__.py\", line 3, in <module>\n",
      "\u001b[1;31m    from .logger import EVENTS_METADATA_VERSION, EventLogger\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jupyter_events/logger.py\", line 14, in <module>\n",
      "\u001b[1;31m    from jsonschema import ValidationError\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jsonschema/__init__.py\", line 13, in <module>\n",
      "\u001b[1;31m    from jsonschema._format import FormatChecker\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jsonschema/_format.py\", line 11, in <module>\n",
      "\u001b[1;31m    from jsonschema.exceptions import FormatError\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/jsonschema/exceptions.py\", line 15, in <module>\n",
      "\u001b[1;31m    from referencing.exceptions import Unresolvable as _Unresolvable\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/referencing/__init__.py\", line 5, in <module>\n",
      "\u001b[1;31m    from referencing._core import Anchor, Registry, Resource, Specification\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/referencing/_core.py\", line 9, in <module>\n",
      "\u001b[1;31m    from rpds import HashTrieMap, HashTrieSet, List\n",
      "\u001b[1;31m  File \"/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/rpds/__init__.py\", line 1, in <module>\n",
      "\u001b[1;31m    from .rpds import *\n",
      "\u001b[1;31mImportError: dlopen(/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/rpds/rpds.cpython-311-darwin.so, 0x0002): tried: '/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/rpds/rpds.cpython-311-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/rpds/rpds.cpython-311-darwin.so' (no such file), '/Users/yunganglog/Library/Python/3.11/lib/python/site-packages/rpds/rpds.cpython-311-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64'))\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mFailed to run jupyter as observable with args notebook --no-browser --notebook-dir=\"/Users/yunganglog/endpointTest/vision-ai-inference-practice/4. video-ai-inference\" --config=/var/folders/xg/ll2c686j3hq46hd560c95dhh0000gn/T/18feee7a-146e-44bc-a807-a12969194780/jupyter_notebook_config.py --NotebookApp.iopub_data_rate_limit=10000000000.0. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# 다운로드할 YouTube URL\n",
    "url = \"\"\n",
    "\n",
    "# yt-dlp 설정\n",
    "ydl_opts = {\n",
    "    \"format\": \"best\",\n",
    "    \"outtmpl\": \"downloaded_video.%(ext)s\",\n",
    "}\n",
    "\n",
    "# 다운로드\n",
    "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download([url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"downloaded_video.mp4\"\n",
    "\n",
    "# 동영상 파일 열기\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# FPS 가져오기\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"FPS:\", fps)\n",
    "\n",
    "# 동영상 파일 닫기\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"downloaded_video.mp4\"\n",
    "\n",
    "# cv2를 이용해 동영상 파일 열기\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 프레임을 저장할 디렉토리 생성\n",
    "output_dir = \"frames\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 프레임 단위로 이미지로 저장\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # 이미지 파일로 프레임 저장\n",
    "    frame_path = os.path.join(output_dir, f\"frame_{frame_count:04d}.jpg\")\n",
    "    cv2.imwrite(frame_path, frame)\n",
    "    frame_count += 1\n",
    "\n",
    "# 동영상 파일 닫기\n",
    "cap.release()\n",
    "print(f\"총 {frame_count}개의 프레임이 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")  # pretrained YOLO8n model\n",
    "\n",
    "# \"frames\" 디렉토리 안에 있는 파일과 폴더 목록을 가져옴\n",
    "frames = os.listdir(\"frames/\")\n",
    "\n",
    "# 원하는 디렉토리 경로 설정\n",
    "directory_path = \"results\"\n",
    "\n",
    "# 디렉토리가 없으면 생성\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "    print(f\"디렉토리 '{directory_path}'가 생성되었어.\")\n",
    "else:\n",
    "    print(f\"디렉토리 '{directory_path}'가 이미 존재해.\")\n",
    "\n",
    "for frame in frames:\n",
    "    # YOLOv8 모델을 사용하여 객체 감지 수행\n",
    "    results = model(\"frames/\" + frame)  # , device=\"mps\" (맥북)\n",
    "\n",
    "    # Process results list\n",
    "    for result in results:\n",
    "        result.save(filename=\"results/\" + frame)  # save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일들이 저장된 디렉토리 경로\n",
    "image_folder = \"results\"  # 이미지 파일들이 있는 폴더 경로\n",
    "fps = int(fps)  # 초당 프레임 수 설정\n",
    "\n",
    "# 이미지 파일 리스트 가져오기 (예: jpg, png 형식)\n",
    "image_files = [\n",
    "    os.path.join(image_folder, img)\n",
    "    for img in sorted(os.listdir(image_folder))\n",
    "    if img.endswith((\".jpg\", \".png\"))\n",
    "]\n",
    "\n",
    "# 이미지 시퀀스를 이용해 클립 생성\n",
    "clip = ImageSequenceClip(image_files, fps=fps)\n",
    "\n",
    "# 동영상 파일로 저장\n",
    "output_path = \"output_video.mp4\"\n",
    "clip.write_videofile(output_path, codec=\"libx264\")\n",
    "\n",
    "print(f\"동영상이 생성되었습니다: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
